{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/matplotlib/__init__.py:1005: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl  \n",
    "mpl.use('Agg')  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import gym\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import multiprocessing\n",
    "import threading\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from helper import *\n",
    "from gridworld_goals import *\n",
    "print \"ready\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "def get_f(m,offsets):\n",
    "    f = np.zeros([len(m),m.shape[1],len(offsets)])\n",
    "    for i,offset in enumerate(offsets):\n",
    "        f[:-offset,:,i] = m[offset:,:] - m[:-offset,:]\n",
    "        if i > 0:\n",
    "            f[-offset:,:,i] = f[-offset:,:,i-1]\n",
    "    return f\n",
    "\n",
    "class ExperienceBuffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self,experience):\n",
    "        if len(list(self.buffer)) + len(list(experience)) >= self.buffer_size:\n",
    "            self.buffer[0:(len(list(experience))+len(list(self.buffer)))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self,size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])\n",
    "\n",
    "print \"ready\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "class DFP_Network():\n",
    "    def __init__(self,a_size,scope,trainer,num_offsets,num_measurements):\n",
    "        with tf.variable_scope(scope):\n",
    "            #Inputs and visual encoding layers\n",
    "            self.observation = tf.placeholder(shape=[None,5,5,3],dtype=tf.float32)\n",
    "            self.measurements = tf.placeholder(shape=[None,num_measurements],dtype=tf.float32)\n",
    "            self.goals = tf.placeholder(shape=[None,num_measurements],dtype=tf.float32)\n",
    "            self.hidden_o = slim.fully_connected(slim.flatten(self.observation),128,activation_fn=tf.nn.elu)\n",
    "            self.hidden_m = slim.fully_connected(slim.flatten(self.measurements),64,activation_fn=tf.nn.elu)\n",
    "            self.hidden_g = slim.fully_connected(slim.flatten(self.goals),64,activation_fn=tf.nn.elu)\n",
    "            hidden_input = tf.concat([self.hidden_o,self.hidden_m,self.hidden_g],1)\n",
    "            hidden_output = slim.fully_connected(hidden_input,256,activation_fn=tf.nn.elu)\n",
    "            #We calculate separate expectation and advantage streams, then combine then later\n",
    "            #This technique is described in https://arxiv.org/pdf/1511.06581.pdf\n",
    "            self.expectation = slim.fully_connected(hidden_output,a_size * num_offsets * num_measurements,\n",
    "                activation_fn=None,\n",
    "                biases_initializer=None)\n",
    "            self.advantages = slim.fully_connected(hidden_output,a_size * num_offsets * num_measurements,\n",
    "                activation_fn=None,\n",
    "                biases_initializer=None)\n",
    "            self.advantages = self.advantages - tf.reduce_mean(self.advantages,reduction_indices=1,keep_dims=True)\n",
    "            self.prediction = self.expectation + self.advantages\n",
    "            #Reshape the predictions to be  [measurements x actions x offsets]\n",
    "            self.prediction = tf.reshape(self.prediction, [-1,num_measurements,a_size,num_offsets])\n",
    "            # We use a softmax with temperate to pick actions. This is instead of e-greedy.\n",
    "            # For more info on action-selection strategies, see: \n",
    "            # goo.gl/oyL5Vx\n",
    "            self.temperature = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "            self.boltzmann = tf.nn.softmax(tf.reduce_sum(self.prediction,reduction_indices=3)/self.temperature)\n",
    "            self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "            self.actions_onehot = tf.one_hot(self.actions,a_size,dtype=tf.float32)\n",
    "            # Select the predictions relevant to the chosen action.\n",
    "            self.pred_action = tf.reduce_sum(self.prediction * tf.reshape(self.actions_onehot,[-1,1,a_size,1]), [2])\n",
    "            #Only the global network need ops for loss functions and gradient updating.\n",
    "            if scope == 'global':\n",
    "                self.target = tf.placeholder(shape=[None,num_measurements,num_offsets],dtype=tf.float32)\n",
    "                #Loss function\n",
    "                self.loss = tf.reduce_sum(tf.squared_difference(self.pred_action,self.target))\n",
    "                #Sparsity of the action distribution\n",
    "                self.entropy = -tf.reduce_sum(self.boltzmann * tf.log(self.boltzmann + 1e-7)) \n",
    "                #Get & apply gradients from network\n",
    "                global_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'global')\n",
    "                self.gradients = tf.gradients(self.loss,global_vars)\n",
    "                self.var_norms = tf.global_norm(global_vars)\n",
    "                grads,self.grad_norms = tf.clip_by_global_norm(self.gradients,9999.0)\n",
    "                self.apply_grads = trainer.apply_gradients(list(zip(grads,global_vars)))\n",
    "\n",
    "print \"ready\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "class Worker():\n",
    "    def __init__(self,game,name,a_size,trainer,model_path,global_episodes,offsets,exp_buff,num_measurements,master,gif_path):\n",
    "        self.name = \"worker_\" + str(name)\n",
    "        self.number = name        \n",
    "        self.offsets = offsets\n",
    "        self.global_net = master\n",
    "        self.exp_buff = exp_buff\n",
    "        self.model_path = model_path\n",
    "        self.gif_path = gif_path\n",
    "        self.trainer = trainer\n",
    "        self.global_episodes = global_episodes\n",
    "        self.increment = self.global_episodes.assign_add(1)\n",
    "        self.episode_deliveries = []\n",
    "        self.episode_lengths = []\n",
    "        self.episode_mean_values = []\n",
    "        self.num_measurements = num_measurements\n",
    "        self.summary_writer = tf.summary.FileWriter(\"train_\"+str(self.number))\n",
    "        #Create the local copy of the network and the tensorflow op to copy global paramters to local network\n",
    "        self.local_DFP = DFP_Network(a_size,self.name,trainer,len(offsets),num_measurements)\n",
    "        self.update_local_ops = update_target_graph('global',self.name)        \n",
    "        self.env = game\n",
    "    \n",
    "    def train(self,rollout,sess):\n",
    "        rollout = np.array(rollout)\n",
    "        measurements = np.vstack(rollout[:,2])\n",
    "        targets = get_f(measurements,self.offsets) #Generate targets using measurements and offsets\n",
    "        rollout[:,4] = list(zip(targets))\n",
    "        self.exp_buff.add(list(zip(rollout)))\n",
    "        #Get a batch of experiences from the buffer and use them to update the global network\n",
    "        if len(self.exp_buff.buffer) > 128:\n",
    "            exp_batch = self.exp_buff.sample(128)\n",
    "            feed_dict = {self.global_net.observation:np.stack(exp_batch[:,0],axis=0),\n",
    "                self.global_net.measurements:np.vstack(exp_batch[:,2]),\n",
    "                self.global_net.temperature:[0.1],\n",
    "                self.global_net.actions:exp_batch[:,1],\n",
    "                self.global_net.target:np.vstack(exp_batch[:,4]),\n",
    "                self.global_net.goals:np.vstack(exp_batch[:,3])}\n",
    "            loss,entropy,g_n,v_n,_ = sess.run([self.global_net.loss,\n",
    "                self.global_net.entropy,\n",
    "                self.global_net.grad_norms,\n",
    "                self.global_net.var_norms,\n",
    "                self.global_net.apply_grads],feed_dict=feed_dict)\n",
    "            return loss / len(rollout), entropy / len(rollout), g_n,v_n\n",
    "        else:\n",
    "            return 0,0,0,0\n",
    "    \n",
    "    def work(self,sess,coord,saver,train):\n",
    "        episode_count = sess.run(self.global_episodes)\n",
    "        self.episode_count = episode_count\n",
    "        total_steps = 0\n",
    "        print(\"Starting worker \" + str(self.number))\n",
    "        with sess.as_default(), sess.graph.as_default():                 \n",
    "            while not coord.should_stop():\n",
    "                sess.run(self.update_local_ops) #Copy parameters from global to local network\n",
    "                episode_buffer = []\n",
    "                episode_frames = []\n",
    "                d = False\n",
    "                t = 0\n",
    "                temp = 0.25 #How spread out we want our action distribution to be\n",
    "                s,o_big,m,g,h = self.env.reset()\n",
    "                self.the_m = m\n",
    "                while d == False:\n",
    "                    #Here is where our goal-switching takes place\n",
    "                    # When the battery charge is below 0.3, we set the goal to optimize battery\n",
    "                    # When the charge is above that value we set the goal to optimize deliveries\n",
    "                    if m[1] <= .3:\n",
    "                        self.g = np.array([0.0,1.0])\n",
    "                    else:\n",
    "                        self.g = np.array([1.0,0.0])\n",
    "                    a_dist = sess.run(self.local_DFP.boltzmann, \n",
    "                        feed_dict={\n",
    "                        self.local_DFP.temperature:[temp],\n",
    "                        self.local_DFP.observation:[s],\n",
    "                        self.local_DFP.measurements:[m],\n",
    "                        self.local_DFP.goals:[self.g]})\n",
    "                    b = self.g*a_dist[0].T\n",
    "                    c = np.sum(b,1)\n",
    "                    c /= c.sum()\n",
    "                    a = np.random.choice(c,p=c)\n",
    "                    a = np.argmax(c == a)\n",
    "                    s1,s1_big,m1,g1,h1,d = self.env.step(a)                        \n",
    "                    episode_buffer.append([s,a,np.array(m),self.g,np.zeros(len(self.offsets))])\n",
    "                    if self.name == 'worker_0' and episode_count % 150 == 0:\n",
    "                        episode_frames.append(set_image_gridworld(s1_big,m1,t+1,g1,h1))\n",
    "                    total_steps += 1\n",
    "                    s = np.copy(s1)\n",
    "                    m = []\n",
    "                    m = m1[:]\n",
    "                    g = g1[:]\n",
    "                    h = h1\n",
    "                    t += 1\n",
    "                    # End the episode after 100 steps\n",
    "                    if t > 100:\n",
    "                        d = True\n",
    "                \n",
    "                self.episode_deliveries.append(m[0])\n",
    "                self.episode_lengths.append(t)\n",
    "                # Update the network using the experience buffer at the end of the episode.\n",
    "                if train == True:\n",
    "                    loss,entropy,g_n,v_n = self.train(episode_buffer,sess)\n",
    "                \n",
    "                # Periodically save gifs of episodes, model parameters, and summary statistics.\n",
    "                if episode_count % 50 == 0 and episode_count != 0:\n",
    "                    if episode_count % 2000 == 0 and self.name == 'worker_0' and train == True:\n",
    "                        saver.save(sess,self.model_path+'/model-'+str(episode_count)+'.cptk')\n",
    "                        print(\"Saved Model\")\n",
    "                    \n",
    "                    if self.name == 'worker_0' and episode_count % 150 == 0:\n",
    "                        time_per_step = 0.25\n",
    "                        self.images = np.array(episode_frames)\n",
    "                        imageio.mimsave(self.gif_path+'/image'+str(episode_count)+'.gif',self.images, duration=time_per_step)\n",
    "                    \n",
    "                    mean_deliveries = np.mean(self.episode_deliveries[-50:])\n",
    "                    mean_length = np.mean(self.episode_lengths[-50:])\n",
    "                    mean_value = np.mean(self.episode_mean_values[-50:])\n",
    "                    summary = tf.Summary()\n",
    "                    summary.value.add(tag='Performance/Deliveries', simple_value=float(mean_deliveries))\n",
    "                    summary.value.add(tag='Performance/Length', simple_value=float(mean_length))\n",
    "                    if train == True:\n",
    "                        summary.value.add(tag='Losses/Loss', simple_value=float(loss))\n",
    "                        summary.value.add(tag='Losses/Grad Norm', simple_value=float(g_n))\n",
    "                    self.summary_writer.add_summary(summary, episode_count)\n",
    "                    self.summary_writer.flush()\n",
    "                if self.name == 'worker_0':\n",
    "                    sess.run(self.increment)\n",
    "                episode_count += 1\n",
    "                self.episode_count = episode_count\n",
    "\n",
    "print \"ready\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_size = 4 # Number of available actions\n",
    "num_measurements = 2 #Number of measurements\n",
    "learning_rate = 1e-3 #Learning ragte\n",
    "offsets = [1,2,4,8,16,32] # Set of temporal offsets\n",
    "load_model = False #Whether to load a saved model\n",
    "train = True #Whether to train the network\n",
    "model_path = './model_goals' #Path to save the model to\n",
    "gif_path = './frames_goals' #Path to save gifs of agent performance to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "exp_buff = ExperienceBuffer()\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "if not os.path.exists(gif_path):\n",
    "    os.makedirs(gif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "master_network = DFP_Network(a_size,'global',trainer,len(offsets),num_measurements) # Generate global network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"): \n",
    "    global_episodes = tf.Variable(0,dtype=tf.int32,name='global_episodes',trainable=False)\n",
    "    num_workers = 2 # Set workers ot number of available CPU threads\n",
    "    workers = []\n",
    "    # Create worker classes\n",
    "    for i in range(num_workers):\n",
    "        workers.append(\n",
    "            Worker(gameEnv(partial=False,size=5),i,a_size,\n",
    "            trainer,model_path,global_episodes,offsets,\n",
    "            exp_buff,num_measurements,master_network,gif_path))\n",
    "    saver = tf.train.Saver(max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize variables...\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device to node 'global_episodes': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nAssignAdd: CPU \nAssign: CPU XLA_CPU XLA_GPU \nIdentity: GPU CPU XLA_CPU XLA_GPU \nVariableV2: CPU XLA_CPU XLA_GPU \n\t [[Node: global_episodes = VariableV2[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]()]]\n\nCaused by op u'global_episodes', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-9b1dfca28048>\", line 2, in <module>\n    global_episodes = tf.Variable(0,dtype=tf.int32,name='global_episodes',trainable=False)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 294, in _init_from_args\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py\", line 128, in variable_op_v2\n    shared_name=shared_name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 708, in _variable_v2\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2334, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'global_episodes': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nAssignAdd: CPU \nAssign: CPU XLA_CPU XLA_GPU \nIdentity: GPU CPU XLA_CPU XLA_GPU \nVariableV2: CPU XLA_CPU XLA_GPU \n\t [[Node: global_episodes = VariableV2[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-33c085ccee47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'initialize variables...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Start each of the workers on a separate thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mworker_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'global_episodes': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nAssignAdd: CPU \nAssign: CPU XLA_CPU XLA_GPU \nIdentity: GPU CPU XLA_CPU XLA_GPU \nVariableV2: CPU XLA_CPU XLA_GPU \n\t [[Node: global_episodes = VariableV2[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]()]]\n\nCaused by op u'global_episodes', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/lib64/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/lib64/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/lib64/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-9b1dfca28048>\", line 2, in <module>\n    global_episodes = tf.Variable(0,dtype=tf.int32,name='global_episodes',trainable=False)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py\", line 294, in _init_from_args\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/state_ops.py\", line 128, in variable_op_v2\n    shared_name=shared_name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 708, in _variable_v2\n    name=name)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2334, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'global_episodes': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.\nColocation Debug Info:\nColocation group had the following types and devices: \nAssignAdd: CPU \nAssign: CPU XLA_CPU XLA_GPU \nIdentity: GPU CPU XLA_CPU XLA_GPU \nVariableV2: CPU XLA_CPU XLA_GPU \n\t [[Node: global_episodes = VariableV2[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        print('initialize variables...')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    # Start each of the workers on a separate thread\n",
    "    worker_threads = []\n",
    "    for worker in workers:\n",
    "        worker_work = lambda: worker.work(sess,coord,saver,train)\n",
    "        thread = threading.Thread(target=(worker_work))\n",
    "        thread.start()\n",
    "        time.sleep(0.5)\n",
    "        worker_threads.append(thread)\n",
    "    \n",
    "    coord.join(worker_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
